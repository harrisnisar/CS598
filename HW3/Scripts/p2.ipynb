{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import random\n",
    "import numpy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(centeredData, numOfComponents):\n",
    "    [U,s,Vt] = la.svd(centeredData)\n",
    "    Uk = U[:,:numOfComponents]\n",
    "    sk = s[:numOfComponents]\n",
    "    Wp = np.diag(sk**-0.5) @ Uk.T\n",
    "    return Wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(data):\n",
    "    fig, axs = plt.subplots(6, 6)\n",
    "\n",
    "    for i in range(6):\n",
    "        for j in range(6):\n",
    "            dataIndex = 6*i+j\n",
    "            axs[i, j].imshow(np.reshape(data[:,dataIndex],(28,28),'F'), cmap=plt.cm.afmhot)\n",
    "    counter = 0\n",
    "    for ax in axs.flatten():\n",
    "        ax.axes.xaxis.set_ticks([])\n",
    "        ax.axes.yaxis.set_ticks([])\n",
    "\n",
    "        counter += 1\n",
    "    fig.set_figheight(8)\n",
    "    fig.set_figwidth(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and set some helper variables\n",
    "data = np.load(\"./Data/digits-labels.npz\")\n",
    "X = data[\"d\"]\n",
    "labels = data[\"l\"]\n",
    "m, n = X.shape # m is number of features and n is number of images\n",
    "k = 36 # k is the number of pc's we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 10000 images of vectorized length 784. We are trying to reduce these images to be 36-dimensional.\n"
     ]
    }
   ],
   "source": [
    "print(f\"We have {n} images of vectorized length {m}. We are trying to reduce these images to be {k}-dimensional.\")\n",
    "#plt.imshow(np.reshape( X[:,0],(28,28),'F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = np.vstack((X, labels))\n",
    "\n",
    "training = []\n",
    "testing = []\n",
    "\n",
    "numClasses = 10\n",
    "\n",
    "for i in range(numClasses):\n",
    "    classi =  dataSet[:,np.squeeze(np.argwhere(labels==i))]\n",
    "    sizeClassi = np.shape(classi)[1]\n",
    "    random100 = random.sample(range(sizeClassi), 100)\n",
    "    conditionals1 = np.full(sizeClassi, False)\n",
    "    conditionals1[random100] = True\n",
    "    training.append(classi[:,conditionals1])\n",
    "    testing.append(classi[:,~conditionals1])\n",
    "\n",
    "training = np.hstack(training)\n",
    "testing = np.hstack(testing)\n",
    "trainingX = training[:784, :]\n",
    "trainingY = training[784, :]\n",
    "testingX = testing[:784, :]\n",
    "testingY = testing[784, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 1000)\n"
     ]
    }
   ],
   "source": [
    "#2. calculate the mean image and center all the training data\n",
    "meanTrainingImage = np.mean(trainingX, axis = 1).reshape(-1, 1)\n",
    "\n",
    "centeredTrainingX = trainingX - meanTrainingImage\n",
    "\n",
    "print(np.shape(centeredTrainingX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 9000)\n"
     ]
    }
   ],
   "source": [
    "#3. run PCA on centered training data covariance to get Wp\n",
    "centeredCovariance = np.cov(centeredTrainingX)\n",
    "\n",
    "Wp = pca(centeredCovariance, k)\n",
    "compressedTrainingX = Wp @ centeredTrainingX\n",
    "compressedTestingX = Wp @ (testingX - meanTrainingImage)\n",
    "Wp_inv = np.linalg.pinv(Wp)\n",
    "print(np.shape(compressedTestingX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotter(Wp_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianDiscriminant:\n",
    "    def __init__(self, rawClassData, classProbability):\n",
    "        self._rawClassData = rawClassData\n",
    "        self.classMean = np.mean(rawClassData, axis=1).reshape((36,1))\n",
    "        self.classCovariance = np.cov(rawClassData)\n",
    "        self.classProbability = classProbability\n",
    "        self.inverseClassCovariance = np.linalg.inv(self.classCovariance)\n",
    "        self.getDiscriminantParameters()\n",
    "        \n",
    "    def getDiscriminantParameters(self):\n",
    "        self.A = (-0.5) * self.inverseClassCovariance\n",
    "        self.b = self.inverseClassCovariance @ self.classMean\n",
    "        self.c = (-0.5) * (self.classMean.T @ self.inverseClassCovariance @ self.classMean + np.log(np.linalg.det(self.classCovariance))) + np.log(self.classProbability)\n",
    "        \n",
    "    def evalGaussianDiscriminantForMany(self, X):\n",
    "        return np.sum((X.T @ self.A) * X.T, axis=1) + self.b.T @ X + self.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GausianClassifier:\n",
    "    def __init__(self, rawData):\n",
    "        self.agregates = {}\n",
    "        for i in range(numClasses):\n",
    "            rawClassIndex = np.squeeze(np.argwhere(trainingY==i))\n",
    "            rawClassData = rawData[:,rawClassIndex]\n",
    "            self.agregates[i] = GaussianDiscriminant(rawClassData, 100/1000)\n",
    "\n",
    "          \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 9000)\n"
     ]
    }
   ],
   "source": [
    "digitClassifier = GausianClassifier(compressedTrainingX)\n",
    "scores = []\n",
    "for i in range(10):\n",
    "    \n",
    "    scores.append(digitClassifier.agregates[i].evalGaussianDiscriminantForMany(compressedTestingX))\n",
    "scores = np.squeeze(scores)\n",
    "print(np.shape(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915\n"
     ]
    }
   ],
   "source": [
    "numCorrect = 0\n",
    "for i in range(9000):\n",
    "    if(np.argmax(scores[:,i]) == int(testingY[i])):\n",
    "        numCorrect += 1\n",
    "print(numCorrect/9000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
